# Iterative Trainer

Iterative fine-tuning is a training method that enables to perform custom actions (generation and filtering for example) between optimization steps. In TRL we provide an easy-to-use API to fine-tune your models in an iterative way in just a few lines of code.

## Usage

To get started quickly, instantiate an instance of the class with an 'IterativeConfig', a model, and a tokenizer.

```python

model = AutoModelForCausalLM.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)
tokenizer.pad_token = tokenizer.eos_token

config = IterativeConfig(
    model_name=model_name,
    log_with=log_with,
    project_kwargs={"logging_dir":logging_dir}
)

trainer = IterativeTrainer(
    config,
    model,
    tokenizer
)

```

And assuming you have a list of tensors of input_ids and attention_mask, you can fine-tune your models on those samples calling the step method

```python

trainer.step(input_ids, attention_mask, None)

```

For causal language models, labels will automatically be created from input_ids. When using sequence to sequence models you will have to provide your own labels.
The default step batch size is 32, but you can change it at the time of instance initialization of the 'IterativeConfig' like so

```python

config = IterativeConfig(
    model_name=model_name,
    step_batch_size=step_batch_size, 
    log_with=log_with,
    project_kwargs={"logging_dir":logging_dir}
)

```

## IterativeTrainer

[[autodoc]] IterativeTrainer

[[autodoc]] IterativeConfig
